defaults:
  - _self_
  - experiment: variants

train: # Not used in generate.py
  name: VariaNTSWords-v4 # Name of experiment (prefix of experiment name)
                         # This will also be used as the W&B run name
  ckpt_epoch: max
  epochs_per_ckpt: 10
  iters_per_logging: 20
  n_epochs: 1
  learning_rate: 2e-4
  batch_size_per_gpu: 8

generate:
  ckpt_epoch: max # Which checkpoint to use; assign a number or "max". Is ignored when sampling during training
  n_samples: 8 # Number of utterances to be generated (per GPU)
  batch_size: null # Number of samples to generate at once per GPU. null means max (equal to samples_per_gpu)
  conditional_file: /home/passch/data/HP1_EEG_conditional/denoised_fixed-transcript_cleaned/dag7.npy # Path to conditional input on disk. Can be null in unconditional setting.

distributed:
  dist_backend: nccl
  dist_url: tcp://localhost:54321

wandb:
  mode: disabled # Pass in 'wandb.mode=online' to turn on wandb logging
  project: diffwave-dutch-unconditional
  entity: pascalschroeder
  id: null # Set to string and pass '+wandb.resume=true' to resume logging from run. 
           # ID of previous run be found in the run's URL on W&B (not the run name)
  job_type: training
